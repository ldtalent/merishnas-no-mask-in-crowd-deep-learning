{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How to create a deep learning classifier to detect people with no mask for COVID-19 in a crowd of people"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](sample_images/cover.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## About the author: \n",
    "\n",
    "[Merishna S](https://www.linkedin.com/in/merishna-ss/) is an Artificial intelligence & Machine Learning engineer with strong fundamentals in machine learning algorithms (neural networks, dimensionality reduction, feature utilization, and extraction and clustering), programming, statistics, and mathematics. \n",
    "\n",
    "## Introduction\n",
    "\n",
    "The [CDC](https://www.cdc.gov/) continues to monitor the spread of COVID-19 and advises people who are completely vaccinated as well as those who are not fully vaccinated to wear face masks. When visiting the doctor's office, hospitals, or long-term care institutions, the CDC recommends wearing masks and keeping a safe distance.Â \n",
    "\n",
    "Manually monitoring people entering such institutions is tedious and requires workforce. In this tutorial, we will learn how we can automate this process through deep learning techniques which will automatically detect people not wearing masks to prevent their entry.\n",
    "\n",
    "## Glossary\n",
    "\n",
    "**Deep Learning:** It is a kind of machine learning technique that enables learning through the use of neural networks that mimic the human brain.\n",
    "\n",
    "## Prerequisites\n",
    "\n",
    "1. Programming knowledge in Python.\n",
    "2. Basic knowledge of Jupyter Notebook, Deep Learning, Keras.\n",
    "\n",
    "## Creating the mask detection deep learning model\n",
    "\n",
    "We will now look into building a Deep Learning model to predict (detect) if a person is violating the rules by not wearing a mask in public spaces."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing Python libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_kg_hide-output": true,
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2022-05-23T11:37:36.995194Z",
     "iopub.status.busy": "2022-05-23T11:37:36.994361Z",
     "iopub.status.idle": "2022-05-23T11:37:43.689840Z",
     "shell.execute_reply": "2022-05-23T11:37:43.688600Z",
     "shell.execute_reply.started": "2022-05-23T11:37:36.995145Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np  # linear algebra\n",
    "import pandas as pd  # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import cv2\n",
    "from scipy.spatial import distance\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "from keras.applications.vgg19 import VGG19\n",
    "from keras.applications.vgg19 import preprocess_input\n",
    "from keras import Sequential\n",
    "from keras.layers import Flatten, Dense\n",
    "from keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Getting the data\n",
    "\n",
    "For the training data, we are using the face mask detection data from [here](https://www.kaggle.com/datasets/ashishjangra27/face-mask-12k-images-dataset). The dataset contains 12 thousand images divided into Test, Train, and Validation sets which were scraped from Google and the CelebFace dataset created by [Jessica Li ](https://www.kaggle.com/jessicali9530). To start using it, you can download the dataset and save it in the working directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load train and test set\n",
    "train_dir = \"data/Train\"\n",
    "test_dir = \"data/Test\"\n",
    "val_dir = \"data/Validation\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Reading a sample image and performing face detection\n",
    "\n",
    "We will now read in a sample image from a busy airport and perform face detection using haar cascade classifier. The [Haar cascade classifier](https://docs.opencv.org/3.4/db/d28/tutorial_cascade_classifier.html), originally known as the Viola-Jones Face Detection Technique is a object detection algorithm for detecting faces in images or real-time video. \n",
    "\n",
    "Viola and Jones proposed edge or line detection features in their research paper \"Rapid Object Detection using a Boosted Cascade of Simple Features,\" published in 2001. The algorithm is given a large number of positive photos with faces and a large number of negative images with no faces. The model developed as a result of this training can be found in the OpenCV GitHub [repository](https://github.com/opencv/opencv/tree/master/data/haarcascades)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-23T10:49:13.289896Z",
     "iopub.status.busy": "2022-05-23T10:49:13.289348Z",
     "iopub.status.idle": "2022-05-23T10:49:13.780488Z",
     "shell.execute_reply": "2022-05-23T10:49:13.779531Z",
     "shell.execute_reply.started": "2022-05-23T10:49:13.289851Z"
    }
   },
   "outputs": [],
   "source": [
    "# Read a sample image\n",
    "img = cv2.imread(\"sample_images/image (24)\")\n",
    "\n",
    "# Keep a copy of coloured image\n",
    "orig_img = cv2.cvtColor(img, cv2.COLOR_RGB2BGR)  # colored output image\n",
    "\n",
    "# Convert image to grayscale\n",
    "img = cv2.cvtColor(img, cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "# loading haarcascade_frontalface_default.xml\n",
    "face_detection_model = cv2.CascadeClassifier(\"data/haarcascade_frontalface_default.xml\")\n",
    "\n",
    "# detect faces in the given image\n",
    "return_faces = face_detection_model.detectMultiScale(\n",
    "    img, scaleFactor=1.1, minNeighbors=4\n",
    ")  # returns a list of (x,y,w,h) tuples\n",
    "\n",
    "# plotting the returned values\n",
    "for (x, y, w, h) in return_faces:\n",
    "    cv2.rectangle(orig_img, (x, y), (x + w, y + h), (0, 0, 255), 1)\n",
    "\n",
    "plt.figure(figsize=(12, 12))\n",
    "plt.imshow(orig_img)  # display the image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Detecting social distancing between people\n",
    "\n",
    "We will now attempt to add a social distancing violation detector between people based on the distance between the coordinates of their faces. If the distance is less than the minimum distance, then they are not following social distancing norms (shown by red bounding box)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-23T10:57:47.794913Z",
     "iopub.status.busy": "2022-05-23T10:57:47.794333Z",
     "iopub.status.idle": "2022-05-23T10:57:48.139553Z",
     "shell.execute_reply": "2022-05-23T10:57:48.137603Z",
     "shell.execute_reply.started": "2022-05-23T10:57:47.794871Z"
    }
   },
   "outputs": [],
   "source": [
    "# minimum distance between two people (approx. 6ft)\n",
    "MIN_SOCIAL_DISTANCE = 130\n",
    "\n",
    "# check if the euclidean distance between the coordinates of faces is less than minimum distance\n",
    "if len(return_faces) >= 2:\n",
    "    label = [0 for i in range(len(return_faces))]\n",
    "    for i in range(len(return_faces) - 1):\n",
    "        for j in range(i + 1, len(return_faces)):\n",
    "            dist = distance.euclidean(return_faces[i][:2], return_faces[j][:2])\n",
    "            # if the distance is less\n",
    "            if dist < MIN_SOCIAL_DISTANCE:\n",
    "                label[i] = 1\n",
    "                label[j] = 1\n",
    "    new_img = cv2.cvtColor(img, cv2.COLOR_RGB2BGR)  # colored output image\n",
    "    for i in range(len(return_faces)):\n",
    "        (x, y, w, h) = return_faces[i]\n",
    "        if label[i] == 1:\n",
    "            cv2.rectangle(\n",
    "                new_img, (x, y), (x + w, y + h), (255, 0, 0), 1\n",
    "            )  # red bounding box (unsafe)\n",
    "        else:\n",
    "            cv2.rectangle(\n",
    "                new_img, (x, y), (x + w, y + h), (0, 255, 0), 1\n",
    "            )  # green bounding box (safe)\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    plt.imshow(new_img)\n",
    "\n",
    "else:\n",
    "    print(\"No. of faces detected is less than 2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Data preprocessing for building the mask detection Keras model\n",
    "\n",
    "We will now pass our datasets into Keras ImageDataGenerator() to perform some preliminary data augmentation steps such as rescaling. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-23T11:37:54.473518Z",
     "iopub.status.busy": "2022-05-23T11:37:54.472778Z",
     "iopub.status.idle": "2022-05-23T11:38:06.553755Z",
     "shell.execute_reply": "2022-05-23T11:38:06.552523Z",
     "shell.execute_reply.started": "2022-05-23T11:37:54.473476Z"
    }
   },
   "outputs": [],
   "source": [
    "# Data preprocessing\n",
    "# Train\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1.0 / 255, horizontal_flip=True, zoom_range=0.2, shear_range=0.2\n",
    ")\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    directory=train_dir, target_size=(128, 128), class_mode=\"categorical\", batch_size=32\n",
    ")\n",
    "\n",
    "# Validation\n",
    "val_datagen = ImageDataGenerator(rescale=1.0 / 255)\n",
    "val_generator = train_datagen.flow_from_directory(\n",
    "    directory=val_dir, target_size=(128, 128), class_mode=\"categorical\", batch_size=32\n",
    ")\n",
    "\n",
    "# Test\n",
    "test_datagen = ImageDataGenerator(rescale=1.0 / 255)\n",
    "test_generator = train_datagen.flow_from_directory(\n",
    "    directory=val_dir, target_size=(128, 128), class_mode=\"categorical\", batch_size=32\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5: Create the mask detection transfer learning model using Keras\n",
    "\n",
    "We are building the deep learning classifer using the VGG19 transfer learning model. The VGG19 model is the successor of AlexNet, a variation of the VGG model named after the group named as Visual Geometry Group at Oxford which created it. It is a deep CNN consisting of 19 layers (16 convolution layers, 3 Fully connected layer, 5 MaxPool layers and 1 SoftMax layer) used to classify images. \n",
    "\n",
    "It has been trained on [ImageNet](https://image-net.org/), a picture database with 14,197,122 images structured according to the WordNet hierarchy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "_kg_hide-output": true,
    "execution": {
     "iopub.execute_input": "2022-05-23T11:38:15.929945Z",
     "iopub.status.busy": "2022-05-23T11:38:15.929488Z",
     "iopub.status.idle": "2022-05-23T11:38:16.639907Z",
     "shell.execute_reply": "2022-05-23T11:38:16.638774Z",
     "shell.execute_reply.started": "2022-05-23T11:38:15.929901Z"
    }
   },
   "outputs": [],
   "source": [
    "vgg19_model = VGG19(weights=\"imagenet\", include_top=False, input_shape=(128, 128, 3))\n",
    "\n",
    "for layer in vgg19_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Initialize a sequential model\n",
    "model = Sequential()\n",
    "model.add(vgg19_model)\n",
    "model.add(Flatten())\n",
    "model.add(Dense(2, activation=\"sigmoid\"))\n",
    "model.summary()\n",
    "\n",
    "model.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=\"accuracy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 6: Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-23T07:59:44.002495Z",
     "iopub.status.busy": "2022-05-23T07:59:44.00221Z",
     "iopub.status.idle": "2022-05-23T08:00:53.49329Z",
     "shell.execute_reply": "2022-05-23T08:00:53.49234Z",
     "shell.execute_reply.started": "2022-05-23T07:59:44.00247Z"
    }
   },
   "outputs": [],
   "source": [
    "# Fit the model on train data along with validation data\n",
    "model_history = model.fit_generator(\n",
    "    generator=train_generator,\n",
    "    steps_per_epoch=len(train_generator) // 32,\n",
    "    epochs=20,\n",
    "    validation_data=val_generator,\n",
    "    validation_steps=len(val_generator) // 32,\n",
    ")\n",
    "\n",
    "# Evaluate model performance on test data\n",
    "model.evaluate_generator(test_generator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 7: Save the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-23T08:01:04.636616Z",
     "iopub.status.busy": "2022-05-23T08:01:04.636104Z",
     "iopub.status.idle": "2022-05-23T08:01:04.813076Z",
     "shell.execute_reply": "2022-05-23T08:01:04.812299Z",
     "shell.execute_reply.started": "2022-05-23T08:01:04.636567Z"
    }
   },
   "outputs": [],
   "source": [
    "model.save('saved_model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7: Test the model on the sample image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now test the trained model on our use case for detecting faces and masks for a group of people. We take the detected face crops of the faces detected in the image and then predict the mask or no mask using the model trained."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-23T08:01:04.815758Z",
     "iopub.status.busy": "2022-05-23T08:01:04.81516Z",
     "iopub.status.idle": "2022-05-23T08:01:04.821132Z",
     "shell.execute_reply": "2022-05-23T08:01:04.819762Z",
     "shell.execute_reply.started": "2022-05-23T08:01:04.815703Z"
    }
   },
   "outputs": [],
   "source": [
    "# label for mask detection\n",
    "mask_det_label = {0: \"MASK\", 1: \"NO MASK\"}\n",
    "# label for social distancing norm\n",
    "social_dist_label = {0: (0, 255, 0), 1: (255, 0, 0)}\n",
    "\n",
    "# If the image contains more than 2 faces\n",
    "if len(return_faces) >= 2:\n",
    "    label = [0 for i in range(len(return_faces))]\n",
    "    for i in range(len(return_faces) - 1):\n",
    "        for j in range(i + 1, len(return_faces)):\n",
    "            # Check the euclidean distance between\n",
    "            dist_between = distance.euclidean(return_faces[i][:2], return_faces[j][:2])\n",
    "            if dist_between < MIN_SOCIAL_DISTANCE:\n",
    "                label[i] = 1\n",
    "                label[j] = 1\n",
    "\n",
    "    main_img = cv2.cvtColor(img, cv2.COLOR_RGB2BGR)  # colored output image\n",
    "    for i in range(len(return_faces)):\n",
    "        (x, y, w, h) = return_faces[i]\n",
    "        cropped_face = main_img[y : y + h, x : x + w]\n",
    "        cropped_face = cv2.resize(cropped_face, (128, 128))\n",
    "        cropped_face = np.reshape(cropped_face, [1, 128, 128, 3]) / 255.0\n",
    "        mask_result = model.predict(cropped_face)\n",
    "        cv2.putText(\n",
    "            main_img,\n",
    "            mask_det_label[mask_result.argmax()],\n",
    "            (x, y - 10),\n",
    "            cv2.FONT_HERSHEY_SIMPLEX,\n",
    "            0.5,\n",
    "            social_dist_label[label[i]],\n",
    "            2,\n",
    "        )\n",
    "        cv2.rectangle(main_img, (x, y), (x + w, y + h), social_dist_label[label[i]], 1)\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    plt.imshow(main_img)\n",
    "\n",
    "else:\n",
    "    print(\"No. of faces detected is less than 2\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
